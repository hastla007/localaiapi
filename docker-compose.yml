version: '3.8'

services:
  comfyui:
    image: yanwk/comfyui-boot:cu128-megapak
    container_name: comfyui-wan21
    ports:
      - "8188:8188"
    volumes:
      # Main storage
      - ./comfyui/storage:/root
      # Models storage (separated for better organization)
      - ./comfyui/storage-models/models:/root/ComfyUI/models
      - ./comfyui/storage-models/hf-hub:/root/.cache/huggingface/hub
      - ./comfyui/storage-models/torch-hub:/root/.cache/torch/hub
      # User directories
      - ./comfyui/storage-user/input:/root/ComfyUI/input
      - ./comfyui/storage-user/output:/root/ComfyUI/output
      - ./comfyui/storage-user/workflows:/root/ComfyUI/user/default/workflows
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=all
      - CLI_ARGS=--listen 0.0.0.0 --port 8188 --fast --disable-xformers
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    shm_size: '16gb'

  ai-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-api-local
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./outputs:/app/outputs
      - ./cache:/app/cache
      - ./templates:/app/templates
      - ./comfyui_workflows:/app/comfyui_workflows
      - ./comfyui_client.py:/app/comfyui_client.py
    env_file:
      - .env  # Loads HF_TOKEN for runtime
    environment:
      - HF_HOME=/app/cache
      - TRANSFORMERS_CACHE=/app/cache
      - CUDA_VISIBLE_DEVICES=0
      - MAX_LOADED_MODELS=2
      - MODEL_TIMEOUT=300
      - TORCH_CUDA_ARCH_LIST=8.0;8.6;8.9;9.0;12.0
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128
      - CUDA_LAUNCH_BLOCKING=0
      - TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
      - COMFYUI_URL=http://comfyui:8188
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    shm_size: '16gb'
    depends_on:
      - comfyui
