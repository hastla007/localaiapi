# Optimized Dockerfile for RTX 5070 Ti / CUDA 12.4.1 / PyTorch 2.4.x
# Combines your original logic with a stable base image and fixes the heredoc syntax

FROM pytorch/pytorch:2.4.0-cuda12.4-cudnn9-runtime

# Environment setup
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    HF_HOME=/root/.cache/huggingface \
    FORCE_CUDA=1 \
    TORCH_CUDA_ARCH_LIST="12.0" \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Install only essentials (no PPA, no GPG headaches)
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3-dev python3-venv \
    git wget curl build-essential \
    libgl1-mesa-glx libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*



# Install pip for Python 3.12
RUN curl -sS https://bootstrap.pypa.io/get-pip.py | python3.12

# Make Python 3.12 the default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 && \
    update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1

# Verify Python and pip versions
RUN python3 --version && pip3 --version

# Upgrade core packaging tools
RUN pip3 install --upgrade pip setuptools wheel

WORKDIR /app

# Ensure latest stable PyTorch 2.4.x CUDA 12.4 build
RUN pip3 install --upgrade torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu124

# Verify PyTorch + GPU access
RUN python3 << 'EOF'
import torch
print('='*60)
print(f'PyTorch Version: {torch.__version__}')
print(f'CUDA Available: {torch.cuda.is_available()}')
print(f'CUDA Runtime: {getattr(torch.version, "cuda", "N/A")}')
print('='*60)

if torch.cuda.is_available():
    print('\nðŸ” GPU Detection Test:')
    print(f'  GPU Name: {torch.cuda.get_device_name(0)}')
    cap = torch.cuda.get_device_capability(0)
    print(f'  Compute Capability: {cap[0]}.{cap[1]}')
    if cap[0] == 12 and cap[1] == 0:
        print('  âœ… Blackwell (sm_120) detected!')
    print(f'  Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')

    print('\nðŸ§ª Tensor Operations Test:')
    x = torch.randn(1000, 1000, device='cuda')
    y = torch.randn(1000, 1000, device='cuda')
    z = torch.matmul(x, y)
    print(f'  Tensor matmul result: {z.mean().item():.6f}')

print('\nâœ… PyTorch GPU test completed successfully!')
EOF

ENTRYPOINT ["/usr/bin/tini", "--"]
CMD ["python3"]
